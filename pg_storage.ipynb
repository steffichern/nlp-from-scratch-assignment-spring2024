{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bccd47fc",
      "metadata": {
        "id": "bccd47fc"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/vector_stores/postgres.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db0855d0",
      "metadata": {
        "id": "db0855d0"
      },
      "source": [
        "# Postgres Vector Store\n",
        "In this notebook we are going to show how to use [Postgresql](https://www.postgresql.org) and  [pgvector](https://github.com/pgvector/pgvector)  to perform vector searches in LlamaIndex"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4f33fc9",
      "metadata": {
        "id": "e4f33fc9"
      },
      "source": [
        "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "52ebbfe3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-index in /home/scott/anaconda3/lib/python3.10/site-packages (0.10.17)\n",
            "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index) (0.9.48)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index) (0.1.3)\n",
            "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index) (0.1.8)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.17 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index) (0.10.17)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index) (0.1.4)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.2.0,>=0.1.4 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index) (0.1.5)\n",
            "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index) (0.1.4)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.5 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index) (0.1.7)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index) (0.1.6)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index) (0.1.3)\n",
            "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index) (0.1.8)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index) (0.1.3)\n",
            "Requirement already satisfied: llama-index-vector-stores-chroma<0.2.0,>=0.1.1 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.1.5)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (1.2.14)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (2.31.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (4.66.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (1.13.3)\n",
            "Requirement already satisfied: dataclasses-json in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (0.6.4)\n",
            "Requirement already satisfied: numpy in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (1.23.5)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (0.6.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (1.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (4.10.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (3.9.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (3.8.1)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (1.0.8)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (0.9.0)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (2.0.28)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (2023.10.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (0.1.13)\n",
            "Requirement already satisfied: pandas in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (1.5.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (8.2.3)\n",
            "Requirement already satisfied: httpx in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (0.27.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (6.0.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (3.2.1)\n",
            "Requirement already satisfied: pymupdf<2.0.0,>=1.23.21 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.23.26)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.1.0)\n",
            "Requirement already satisfied: bs4<0.0.3,>=0.0.2 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.2)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
            "Requirement already satisfied: llama-parse<0.4.0,>=0.3.3 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index) (0.3.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.17->llama-index) (22.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/scott/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.17->llama-index) (4.0.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/scott/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/scott/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.17->llama-index) (6.0.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/scott/anaconda3/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.3.2.post1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /home/scott/anaconda3/lib/python3.10/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.14.1)\n",
            "Requirement already satisfied: onnxruntime<2.0.0,>=1.17.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.17.1)\n",
            "Requirement already satisfied: tokenizers<0.16.0,>=0.15.1 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.15.2)\n",
            "Requirement already satisfied: chromadb<0.5.0,>=0.4.22 in /home/scott/anaconda3/lib/python3.10/site-packages (from llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.4.24)\n",
            "Requirement already satisfied: pydantic>=1.10 in /home/scott/anaconda3/lib/python3.10/site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.17->llama-index) (2.6.3)\n",
            "Requirement already satisfied: idna in /home/scott/anaconda3/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.17->llama-index) (3.4)\n",
            "Requirement already satisfied: sniffio in /home/scott/anaconda3/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in /home/scott/anaconda3/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.0.4)\n",
            "Requirement already satisfied: anyio in /home/scott/anaconda3/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.17->llama-index) (3.5.0)\n",
            "Requirement already satisfied: certifi in /home/scott/anaconda3/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.17->llama-index) (2023.7.22)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /home/scott/anaconda3/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.17->llama-index) (0.14.0)\n",
            "Requirement already satisfied: joblib in /home/scott/anaconda3/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.1.1)\n",
            "Requirement already satisfied: click in /home/scott/anaconda3/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.17->llama-index) (8.0.4)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /home/scott/anaconda3/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.17->llama-index) (2022.7.9)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.9.0)\n",
            "Requirement already satisfied: PyMuPDFb==1.23.22 in /home/scott/anaconda3/lib/python3.10/site-packages (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.23.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/scott/anaconda3/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.17->llama-index) (2.0.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/scott/anaconda3/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.26.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /home/scott/anaconda3/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.17->llama-index) (2.0.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.17->llama-index) (0.4.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.17->llama-index) (3.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /home/scott/anaconda3/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.17->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/scott/anaconda3/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.17->llama-index) (2022.7)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /home/scott/anaconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.48.9)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /home/scott/anaconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (4.1.2)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /home/scott/anaconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.44b0)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /home/scott/anaconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (7.7.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /home/scott/anaconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (4.1.0)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /home/scott/anaconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.7.3)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.62.0)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /home/scott/anaconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.110.0)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (3.5.0)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (3.4.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /home/scott/anaconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.1.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /home/scott/anaconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (3.9.15)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /home/scott/anaconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.27.1)\n",
            "Requirement already satisfied: importlib-resources in /home/scott/anaconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (6.1.2)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (29.0.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.23.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.9.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.23.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.17->llama-index) (22.0)\n",
            "Requirement already satisfied: coloredlogs in /home/scott/anaconda3/lib/python3.10/site-packages (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (15.0.1)\n",
            "Requirement already satisfied: protobuf in /home/scott/anaconda3/lib/python3.10/site-packages (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (3.20.3)\n",
            "Requirement already satisfied: sympy in /home/scott/anaconda3/lib/python3.10/site-packages (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.11.1)\n",
            "Requirement already satisfied: flatbuffers in /home/scott/anaconda3/lib/python3.10/site-packages (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (23.5.26)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /home/scott/anaconda3/lib/python3.10/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.17->llama-index) (2.16.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.17->llama-index) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /home/scott/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.16.0)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /home/scott/anaconda3/lib/python3.10/site-packages (from tokenizers<0.16.0,>=0.15.1->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.20.3)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (2.0.1)\n",
            "Requirement already satisfied: pyproject_hooks in /home/scott/anaconda3/lib/python3.10/site-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.0.0)\n",
            "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /home/scott/anaconda3/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.36.3)\n",
            "Requirement already satisfied: filelock in /home/scott/anaconda3/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.1->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (3.13.1)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /home/scott/anaconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (2.28.1)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.58.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /home/scott/anaconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (3.2.2)\n",
            "Requirement already satisfied: requests-oauthlib in /home/scott/anaconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (6.11.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.23.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/scott/anaconda3/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.62.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.23.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.44b0 in /home/scott/anaconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.44b0 in /home/scott/anaconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.44b0 in /home/scott/anaconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.44b0 in /home/scott/anaconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.44b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (65.6.3)\n",
            "Requirement already satisfied: asgiref~=3.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (3.7.2)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (2.2.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /home/scott/anaconda3/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.6)\n",
            "Requirement already satisfied: websockets>=10.4 in /home/scott/anaconda3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (12.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /home/scott/anaconda3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.21.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.6.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.19.0)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /home/scott/anaconda3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.0.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /home/scott/anaconda3/lib/python3.10/site-packages (from coloredlogs->onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/scott/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.2.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/scott/anaconda3/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/scott/anaconda3/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/scott/anaconda3/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (4.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/scott/anaconda3/lib/python3.10/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/scott/anaconda3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.4.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c2d1c538",
      "metadata": {
        "id": "c2d1c538"
      },
      "outputs": [],
      "source": [
        "# import logging\n",
        "# import sys\n",
        "\n",
        "# Uncomment to see debug logs\n",
        "# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
        "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
        "\n",
        "from llama_index.core import SimpleDirectoryReader, StorageContext\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.vector_stores.postgres import PGVectorStore\n",
        "import textwrap\n",
        "import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26c71b6d",
      "metadata": {
        "id": "26c71b6d"
      },
      "source": [
        "### Setup OpenAI\n",
        "The first step is to configure the openai key. It will be used to created embeddings for the documents loaded into the index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "67b86621",
      "metadata": {
        "id": "67b86621"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import dotenv\n",
        "\n",
        "# Reload the variables in your '.env' file (override the existing variables)\n",
        "dotenv.load_dotenv(\"../.env\", override=True)\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"] "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49ab5a1e",
      "metadata": {},
      "source": [
        "Local Embedding Models\n",
        "\n",
        "The easiest way to use a local model is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "560eb92c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.embed_model = HuggingFaceEmbedding(\n",
        "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7010b1d-d1bb-4f08-9309-a328bb4ea396",
      "metadata": {
        "id": "f7010b1d-d1bb-4f08-9309-a328bb4ea396"
      },
      "source": [
        "### Loading documents\n",
        "Load the documents stored in the `data/faculty_websites/` using the SimpleDirectoryReader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c154dd4b",
      "metadata": {
        "id": "c154dd4b",
        "outputId": "e145d64c-7f0e-418f-bf04-c7be01388782"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document ID: 07a6e5e2-ecb2-437c-81da-84ec06318cd0\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "reader = SimpleDirectoryReader(\n",
        "    input_files=[\"./data/faculty_websites/Bhiksharaj_lti_page.txt\"]\n",
        ")\n",
        "docs = reader.load_data()\n",
        "# print(f\"Loaded {len(docs)} docs\")\n",
        "print(\"Document ID:\", docs[0].doc_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bd24f0a",
      "metadata": {
        "id": "7bd24f0a"
      },
      "source": [
        "### Create the Database\n",
        "Using an existing postgres running at localhost, create the database we'll be using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "e6d61e73",
      "metadata": {
        "id": "e6d61e73"
      },
      "outputs": [],
      "source": [
        "import psycopg2\n",
        "\n",
        "# Reload the variables in your '.env' file (override the existing variables)\n",
        "dotenv.load_dotenv(\"../.env\", override=True)\n",
        "pwd = os.environ['PG_PASSWORD_RAG']\n",
        "user = \"711-rag\"\n",
        "connection_string = f\"dbname=postgres user='{user}' password={pwd}\"\n",
        "db_name = \"711_rag\"\n",
        "conn = psycopg2.connect(connection_string)\n",
        "conn.autocommit = True\n",
        "\n",
        "with conn.cursor() as c:\n",
        "    c.execute(f\"DROP DATABASE IF EXISTS \\\"{db_name}\\\"\")\n",
        "    c.execute(f\"CREATE DATABASE \\\"{db_name}\\\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0232fd1",
      "metadata": {
        "id": "c0232fd1"
      },
      "source": [
        "### Create the index\n",
        "Here we create an index backed by Postgres using the documents loaded previously. PGVectorStore takes a few arguments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "8731da62",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "1358441c0c864d87a860820ed8cf2b2c",
            "69a77c77ff1c48cc8107b445ae4fa0cc"
          ]
        },
        "id": "8731da62",
        "outputId": "07d4a9a7-7d10-4483-e2a8-41573db5928d"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import make_url\n",
        "\n",
        "# url = make_url(connection_string)\n",
        "vector_store = PGVectorStore.from_params(\n",
        "    database=db_name,\n",
        "    host=\"localhost\",\n",
        "    password=pwd,\n",
        "    port=5432,\n",
        "    user=user,\n",
        "    table_name=\"all\",\n",
        "    embed_dim=384, \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6272137c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.llms.replicate import Replicate\n",
        "from llama_index.core.llms.llama_utils import (\n",
        "    messages_to_prompt,\n",
        "    completion_to_prompt,\n",
        ")\n",
        "\n",
        "# The replicate endpoint\n",
        "LLAMA_13B_V2_CHAT = \"a16z-infra/llama13b-v2-chat:df7690f1994d94e96ad9d568eac121aecf50684a0b0963b25a41cc40061269e5\"\n",
        "\n",
        "\n",
        "# inject custom system prompt into llama-2\n",
        "def custom_completion_to_prompt(completion: str) -> str:\n",
        "    return completion_to_prompt(\n",
        "        completion,\n",
        "        system_prompt=(\n",
        "            \"You are a Q&A assistant. Your goal is to answer questions as \"\n",
        "            \"accurately as possible is the instructions and context provided.\"\n",
        "        ),\n",
        "    )\n",
        "\n",
        "\n",
        "llm = Replicate(\n",
        "    model=LLAMA_13B_V2_CHAT,\n",
        "    temperature=0.01,\n",
        "    # override max tokens since it's interpreted\n",
        "    # as context window instead of max tokens\n",
        "    context_window=50,\n",
        "    # override completion representation for llama 2\n",
        "    completion_to_prompt=custom_completion_to_prompt,\n",
        "    # if using llama 2 for data agents, also override the message representation\n",
        "    messages_to_prompt=messages_to_prompt,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53021416",
      "metadata": {},
      "outputs": [],
      "source": [
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    docs, storage_context=storage_context, show_progress=True\n",
        ")\n",
        "query_engine = index.as_query_engine()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ee4473a-094f-4d0a-a825-e1213db07240",
      "metadata": {
        "id": "8ee4473a-094f-4d0a-a825-e1213db07240"
      },
      "source": [
        "### Query the index\n",
        "We can now ask questions using our index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0a2bcc07",
      "metadata": {
        "id": "0a2bcc07"
      },
      "outputs": [],
      "source": [
        "response = query_engine.query(\"Describe the role of I/O service?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8cf55bf7",
      "metadata": {
        "id": "8cf55bf7",
        "outputId": "e8826e64-89c6-47cc-ffe1-3774a441a4cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The I/O service in the context of the given information is responsible for handling I/O requests\n",
            "made by the execution engine for a specific object. It acts as an interface between the execution\n",
            "engine and the storage system, which could be a cloud object-store like Amazon S3. The I/O service\n",
            "is responsible for fetching data from the blob store through the blob cache microservice. It may\n",
            "also retain a copy of the data on local disk storage based on the caching policy, allowing it to\n",
            "service future requests for the same blob more efficiently.\n"
          ]
        }
      ],
      "source": [
        "print(textwrap.fill(str(response), 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3bed9e1",
      "metadata": {
        "id": "b3bed9e1"
      },
      "source": [
        "### Querying existing index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6b2634b",
      "metadata": {
        "id": "e6b2634b"
      },
      "outputs": [],
      "source": [
        "vector_store = PGVectorStore.from_params(\n",
        "    database=\"vector_db\",\n",
        "    host=\"localhost\",\n",
        "    password=\"password\",\n",
        "    port=5432,\n",
        "    user=\"postgres\",\n",
        "    table_name=\"paul_graham_essay\",\n",
        "    embed_dim=1536,  # openai embedding dimension\n",
        ")\n",
        "\n",
        "index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\n",
        "query_engine = index.as_query_engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7075af3-156e-4bde-8f76-6d9dee86861f",
      "metadata": {
        "id": "e7075af3-156e-4bde-8f76-6d9dee86861f"
      },
      "outputs": [],
      "source": [
        "response = query_engine.query(\"What did the author do?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b088c090",
      "metadata": {
        "id": "b088c090",
        "outputId": "8cff0c6b-083f-455f-9f77-c625e15b786b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The author worked on writing and programming before college. They wrote short stories and tried\n",
            "writing programs on an IBM 1401 computer. They also built a microcomputer and started programming on\n",
            "it, writing simple games and a word processor. In college, the author initially planned to study\n",
            "philosophy but switched to AI due to their interest in intelligent computers. They taught themselves\n",
            "AI by learning Lisp.\n"
          ]
        }
      ],
      "source": [
        "print(textwrap.fill(str(response), 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55745895-8f01-4275-abaa-b2ebef2cb4c7",
      "metadata": {
        "id": "55745895-8f01-4275-abaa-b2ebef2cb4c7"
      },
      "source": [
        "### Hybrid Search  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91cae40f-3cd4-4403-8af4-aca2705e96a2",
      "metadata": {
        "id": "91cae40f-3cd4-4403-8af4-aca2705e96a2"
      },
      "source": [
        "To enable hybrid search, you need to:\n",
        "1. pass in `hybrid_search=True` when constructing the `PGVectorStore` (and optionally configure `text_search_config` with the desired language)\n",
        "2. pass in `vector_store_query_mode=\"hybrid\"` when constructing the query engine (this config is passed to the retriever under the hood). You can also optionally set the `sparse_top_k` to configure how many results we should obtain from sparse text search (default is using the same value as `similarity_top_k`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65a7e133-39da-40c5-b2c5-7af2c0a3a792",
      "metadata": {
        "id": "65a7e133-39da-40c5-b2c5-7af2c0a3a792",
        "outputId": "bd4eed92-b4c2-47e2-8666-0d54a95fa8c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/suo/dev/llama_index/llama_index/vector_stores/postgres.py:217: SAWarning: TypeDecorator TSVector() will not produce a cache key because the ``cache_ok`` attribute is not set to True.  This can have significant performance implications including some performance degradations in comparison to prior SQLAlchemy versions.  Set this attribute to True if this type object's state is safe to use in a cache key, or False to disable this warning. (Background on this warning at: https://sqlalche.me/e/20/cprf)\n",
            "  session.commit()\n"
          ]
        }
      ],
      "source": [
        "from sqlalchemy import make_url\n",
        "\n",
        "url = make_url(connection_string)\n",
        "hybrid_vector_store = PGVectorStore.from_params(\n",
        "    database=db_name,\n",
        "    host=url.host,\n",
        "    password=url.password,\n",
        "    port=url.port,\n",
        "    user=url.username,\n",
        "    table_name=\"paul_graham_essay_hybrid_search\",\n",
        "    embed_dim=1536,  # openai embedding dimension\n",
        "    hybrid_search=True,\n",
        "    text_search_config=\"english\",\n",
        ")\n",
        "\n",
        "storage_context = StorageContext.from_defaults(\n",
        "    vector_store=hybrid_vector_store\n",
        ")\n",
        "hybrid_index = VectorStoreIndex.from_documents(\n",
        "    documents, storage_context=storage_context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f8edee4-6c19-4d99-b602-110bdc5708e5",
      "metadata": {
        "id": "6f8edee4-6c19-4d99-b602-110bdc5708e5"
      },
      "outputs": [],
      "source": [
        "hybrid_query_engine = hybrid_index.as_query_engine(\n",
        "    vector_store_query_mode=\"hybrid\", sparse_top_k=2\n",
        ")\n",
        "hybrid_response = hybrid_query_engine.query(\n",
        "    \"Who does Paul Graham think of with the word schtick\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd454b25-b66c-4733-8ff4-24fb2ee84cec",
      "metadata": {
        "id": "bd454b25-b66c-4733-8ff4-24fb2ee84cec",
        "outputId": "861171c6-2cd8-4d18-9646-498a5b6d5434"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Roy Lichtenstein\n"
          ]
        }
      ],
      "source": [
        "print(hybrid_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b274ecb",
      "metadata": {
        "id": "2b274ecb"
      },
      "source": [
        "### PgVector Query Options"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a490a0fa",
      "metadata": {
        "id": "a490a0fa"
      },
      "source": [
        "#### IVFFlat Probes\n",
        "\n",
        "Specify the number of [IVFFlat probes](https://github.com/pgvector/pgvector?tab=readme-ov-file#query-options) (1 by default)\n",
        "\n",
        "When retrieving from the index, you can specify an appropriate number of IVFFlat probes (higher is better for recall, lower is better for speed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "111a3682",
      "metadata": {
        "id": "111a3682"
      },
      "outputs": [],
      "source": [
        "retriever = index.as_retriever(\n",
        "    vector_store_query_mode=query_mode,\n",
        "    similarity_top_k=top_k,\n",
        "    vector_store_kwargs={\"ivfflat_probes\": 10},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6104ef8d",
      "metadata": {
        "id": "6104ef8d"
      },
      "source": [
        "#### HNSW EF Search\n",
        "\n",
        "Specify the size of the dynamic [candidate list](https://github.com/pgvector/pgvector?tab=readme-ov-file#query-options-1) for search (40 by default)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3a44758",
      "metadata": {
        "id": "f3a44758"
      },
      "outputs": [],
      "source": [
        "retriever = index.as_retriever(\n",
        "    vector_store_query_mode=query_mode,\n",
        "    similarity_top_k=top_k,\n",
        "    vector_store_kwargs={\"hnsw_ef_search\": 300},\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
