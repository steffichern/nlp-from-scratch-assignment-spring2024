Title: GPT-Sentinel: Distinguishing Human and ChatGPT Generated Content
Year: 2023
Authors: Yutian Chen, Hao Kang, Vivian Zhai, Liang Li, Rita Singh, B. Ramakrishnan
Abstract: This paper presents a novel approach for detecting ChatGPT-generated vs. human-written text using language models. To this end, we first collected and released a pre-processed dataset named OpenGPTText, which consists of rephrased content generated using ChatGPT. We then designed, implemented, and trained two different models for text classification, using Robustly Optimized BERT Pretraining Approach (RoBERTa) and Text-to-Text Transfer Transformer (T5), respectively. Our models achieved remarkable results, with an accuracy of over 97% on the test dataset, as evaluated through various metrics. Furthermore, we conducted an interpretability study to showcase our model's ability to extract and differentiate key features between human-written and ChatGPT-generated text. Our findings provide important insights into the effective use of language models to detect generated text.
Publication Venue: arXiv.org
TLDR: {'model': 'tldr@v2.0.0', 'text': 'This paper designed, implemented, and trained two different models for text classification, using Robustly Optimized BERT Pretraining Approach (RoBERTa) and Text-to-Text Transfer Transformer (T5), respectively, and achieved remarkable results, with an accuracy of over 97% on the test dataset.'}

Full paper text:
GPT-Sentinel: Distinguishing Human and ChatGPT
Generated Content
Yutian Cheny
School of Computer Science
Carnegie Mellon University
Pittsburgh, PA 15213
yutianch@andrew.cmu.eduHao Kangy
School of Computer Science
Carnegie Mellon University
Pittsburgh, PA 15213
haok@andrew.cmu.eduVivian Zhaiy
College of Engineering
Carnegie Mellon University
Pittsburgh, PA 15213
yiyanz@andrew.cmu.edu
Liangze Li
Language Technologies Institute
Carnegie Mellon University
Pittsburgh, PA 15213
liangzel@andrew.cmu.eduRita Singh
Language Technologies Institute
Carnegie Mellon University
Pittsburgh, PA 15213
rsingh@cs.cmu.edu
Bhiksha Raj
Language Technologies Institute
Carnegie Mellon University
Pittsburgh, PA 15213
bhiksha@cs.cmu.edu
Abstract
This paper presents a novel approach for detecting ChatGPT-generated vs. human-
written text using language models. To this end, we ﬁrst collected and released a
pre-processed dataset named OpenGPTText , which consists of rephrased content
generated using ChatGPT. We then designed, implemented, and trained two dif-
ferent models for text classiﬁcation, using Robustly Optimized BERT Pretraining
Approach (RoBERTa) and Text-to-Text Transfer Transformer (T5), respectively.
Our models achieved remarkable results, with an accuracy of over 97% on the
test dataset, as evaluated through various metrics. Furthermore, we conducted an
interpretability study to showcase our model’s ability to extract and differentiate
key features between human-written and ChatGPT-generated text. Our ﬁndings
provide important insights into the effective use of language models to detect
generated text.
1 Introduction
The development of an algorithm that can accurately distinguish between machine-generated text and
human-generated text has become crucial in contexts where verifying the authenticity of information is
essential, such as in legal proceedings and news reporting. Although traditional statistical techniques
such as logistic regression and support vector machines (SVM) have been used for this purpose in the
past [ 1], the emergence of Large Language Models (LLMs) like InstructGPT [ 2] and the availability
of its free deployment, ChatGPT, has presented signiﬁcant challenges to existing detection methods.
As a result, the need to develop novel algorithms that can accurately distinguish between machine
and human-generated text has become more pressing than ever before.
yThree authors contribute equally to this work.arXiv:2305.07969v2  [cs.CL]  17 May 2023
To address this issue, we focused on ﬁne-tuning approaches to distinguish human-written and
ChatGPT-generated text. We ﬁrst collected the data from ChatGPT and established the OpenGPTText
data set. Section 3 of the paper provides a detailed description of the data collection process, including
the criteria to select the samples and the methods to ﬁlter out irrelevant and undesired noise in the
collected text. We then trained the frozen RoBERTa with MLP and ﬁne-tuned the T5 model on this
data set for classiﬁcation. The resulting model is what we referred to as GPT-Sentinel . More details
about the model can be found in Section 4 of the paper.
The rest of this paper is structured as follows: We ﬁrst discuss related work in Section 2; illustrate
OpenGPTText data set in Section 3; present our model and the training details in Section 4; evaluate
the performance using various metrics in Section 5; interpret the basis for the model’s prediction in
Section 6; point out future work in Section 7; and conclude in Section 8.
2 Related Work
The work by Jawahar et al. identiﬁed ﬁve key characteristics that a state-of-the-art detector for content
generated by LLMs should possess: accuracy ,data efﬁciency ,generalizability , and interpretability
[3]; where accuracy means the model should be able to distinguish between LLM-generated and
human-written text while achieving an appropriate trade-off between precision and recall rates; data
efﬁciency means that the detector should be able to operate with as few examples as possible from
the language model; generalizability means that the detector should be able to work consistently,
regardless of any change in the model architecture, prompt length, or training dataset; interpretability
means the detector should provide clear explanations for the reasoning behind its decisions. These
ﬁve principles is used as our guidance when designing the GPT-Sentinel.
Approaches to machine-generated text detection can be divided into three categories: traditional
statistical approach (by analyzing statistical abnormality in text sample), unsupervised-learning
approach (by zero-shot classiﬁcation of LLM), and supervised-learning approach (by ﬁne-tuning a
language model with or without a classiﬁcation module attached).
2.1 Statistical Methods
The ﬁrst approach to the problem is via the use of statistics. For instance, the work by Solaiman et
al. [4] demonstrated that using a logistic regression model to differentiate between text generated
by GPT-2 models vs. text written by humans could achieve an accuracy ranging from 88% (on 124
million parameter variants of GPT-2 model) to 74% (on 1.5 billion parameter variants of GPT-2
model). Moreover, the work by Ippolito et al. [ 5] showed that the top- ksampling method used
in popular LLMs could over-sample high-likelihood words, and thus the generated text exhibited
statistical anomalies, which could be further used for detection. Moreover, the statistical methods
called the Giant Language Model Test Room (GLTR) designed by Gehrmann et al. [ 6] consists of
three tests: Tests 1 and 2 checked if a generated word is sampled from the top of the distribution,
and Test 3 veriﬁed if the system is overly conﬁdent in its next prediction due to familiarity with
the previously generated context. A human-subject study found that GLTR improved the human
detection rate of fake text from 54% to 72% without prior training.
2.2 Zero-Shot Classiﬁcation
The second detection approach is by zero-shot classiﬁcation (i.e., using a pre-trained LLM to detect its
own generation or that of a similar model). In the work by Solaiman et al. [ 4], a baseline method that
used an LLM to evaluate the log-probability and the corresponding threshold for making classiﬁcation
decisions was proposed. However, this zero-shot approach performs poorly compared to the statistical
methods.
2.3 Fine-Tuning Language Model
The last approach is to ﬁne-tune an existing language model. For example, Zeller et al. [ 7] ﬁne-tuned
a linear layer to identify if the input was generated by the GROVER model or by a human, using
the hidden states in the encoder of GROVER. Also, Solaiman et al. [ 1,4] ﬁne-tuned a pre-trained
RoBERTa model on a labeled dataset to create a content detector that achieved state-of-the-art
2
Table 1: Detailed statistics for OpenGPTText data set as of Apr 24, 2023. The subsets not listed in
the table were not paraphrased in OpenGPTText . The category “Failed to Rephrase” corresponds to
one of the following situations: 1. the content length exceeds the API limit, 2. the content is blocked
by OpenAI content ﬁlter.
Subset OpenGPTText OpenWebText Failed to Rephrase Percentage
urlsf_00 3;888 391 ;590 27 0 :99%
urlsf_01 3;923 392 ;347 0 1 :00%
urlsf_02 3;260 391 ;274 652 0 :83%
urlsf_03 3;891 390 ;161 10 1 :00%
urlsf_04 3;684 390 ;250 218 0 :94%
urlsf_05 3;602 389 ;874 296 0 :92%
urlsf_06 3;494 390 ;339 409 0 :90%
urlsf_09 3;653 389 ;634 243 0 :94%
Total 29;395 3 ;125;469 1 ;885 0 :94%
performance of 90% accuracy in detecting text generated by GPT-2. However, the supervised learning
method requires a large amount of labeled data, in contrast to previously discussed methods. The
ﬁne-tuned model on RoBERTa by Solaiman et al. required 200k labeled training data.
3 Data Set Collection
ChatGPT is a language model based on the GPT-3.5 architecture. It succeeded InstructGPT, which
was previously published by Ouyang et al. [ 2]. As it was introduced by OpenAI on November
30, 2022, there is currently no publicly available data set that systematically collects the outputs
generated by ChatGPT as far as we know. Consequently, we undertook the task of creating our own
data set for ChatGPT outputs. Building upon the work of Gokaslan et al. [ 8] and their OpenWebText
corpus. We named the data set OpenGPTText .
3.1 OpenGPTText Overview
TheOpenGPTText data set consists of paraphrased textual samples that were generated by the
gpt-3.5-turbo language model using the OpenWebText corpus as its source. The data set contains
29,395 textual samples, each corresponding to a piece human-written text from the OpenWebText
corpus that shares a same unique identiﬁer (UID).
Up to April 24, 2023, the OpenGPTText only contains approximately 1% of paraphrased samples of
theOpenWebText data set in some speciﬁc subsets. The number of samples in each subset is listed
in table 1.
3.2 Data Source
TheOpenWebText data set [ 8] is a publicly available resource that comprises web content sourced
from URLs shared on Reddit with a minimum of three votes. This data set is a reconstitution of the
original WebText corpus, which was initially described by Radford et al. [ 9]. Since the data set was
compiled in 2019, it is improbable that the textual content it contains was algorithmically generated.
3.3 Data Collection Method
The rephrasing procedure used OpenAI’s API on gpt-3.5-turbo model, with the prompted instruc-
tion: “ Rephrase the following paragraph by paragraph ”. However, it should be noted that
the samples with length larger than 2,000 words were ﬁltered out as the gpt-3.5-turbo can only
take in at most 3,000 tokens. Some text samples blocked by OpenAI content ﬁlter was also excluded
from OpenGPTText . The number of texts that were not successfully paraphrased due to either of the
two reasons is reported in the “Failed to Rephrase” column in table 1.
3
3
 2
 1
 0 1 2 3 4 51
0123PCA projection of hidden state of
RoBERT a-Sentinel on OpenWebT ext before and after sanitize
OpenWebT ext-Original
OpenWebT ext-Final
4
 3
 2
 1
 0 1 20.5
0.00.51.01.52.0PCA projection of hidden state of
RoBERT a-Sentinel on OpenGPTT ext before and after sanitize
OpenGPTT ext-Original
OpenGPTT ext-FinalFigure 1: PCA of hidden state distribution of RoBERTa-Sentinel model on OpenWebText (Left)
andOpenGPTText (Right) before and after cleaning. Note that the cleaning process affected the
distribution of OpenWebText signiﬁcantly.
3.4 Data Set Cleaning
Upon inspecting the OpenGPTText data set, we observed certain stylistic disparities between Chat-
GPT’s output and the corpus in OpenWebText . Speciﬁcally, our analysis revealed that ChatGPT’s
output tend to include the Unicode character “right double quotation mark” (U+201D) in place of
the ASCII character “quotation mark” (U+0022) used in the OpenWebText corpus. Furthermore,
ChatGPT also tends to incorporate two consecutive new-line characters between paragraphs, whereas
theOpenWebText corpus utilizes two to six new-line characters consecutively.
In an effort to enhance the resilience of our classiﬁer and eliminate the potential inﬂuence of these
susceptible features, we undertook measures to sanitize both the OpenWebText andOpenGPTText
data sets. To achieve this, we implemented a cleaning procedure that involved removing excessive
new-line characters and mapping Unicode characters onto the ASCII character set. These steps were
taken to mitigate any possible confounding effects of these variables on the performance of our
classiﬁer. Pincipal Component Analysis (PCA) of hidden state distribution in ﬁgure 1 shows that the
cleaning process has signiﬁcantly changed the distribution of dataset.
The resulting, clean data set are called OpenWebText-Final andOpenGPTText-Final in the
discussion below.
3.5 Data Set Release
Our plan entails the release of both OpenGPTText andOpenGPTText-Final on Kaggle in May
2023.
4 Method
The following models were trained using the OpenWebText-Final andOpenGPTText-Final data
set, partitioning 80% of the data set for training, 10% for validation, and the remaining 10% for
testing. Given that the texts in the data set have varying lengths, we truncated input text to a maximum
of 512 tokens to improve training efﬁciency, while also padding any text with less than 512 tokens
with additional <PAD> tokens. To address memory constraints while using a relatively large batch
size during ﬁne-tuning, we performed gradient accumulation, whereby the optimizer was updated
after a certain number of forward passes.
4.1 RoBERTa-Sentinel Model
The ﬁrst method we proposed is to leverage the pretrained RoBERTa model [ 10] to extract relevant
features from the input text, followed by an MLP with gaussian error linear units (GELU, [ 11]) and
two fully connected layers for classiﬁcation. To preserve the general linguistic knowledge of the
4
𝐸[𝐶𝐿𝑆] 𝐸1 𝐸2 𝐸𝑁𝑇𝐶𝐿𝑆(1)𝑇1(1)𝑇21𝑇𝑁1
……𝑇[𝐶𝐿𝑆](12)𝑇112𝑇2(12)𝑇𝑁12 …𝑇[𝐶𝐿𝑆] 𝑇1 𝑇2 𝑇𝑁…RoBERTa -Base
This is GPT …MLP…
…𝑃(Human)
𝑃(ChatGPT)…………
𝑇𝐶𝐿𝑆(2)𝑇1(2)𝑇22𝑇𝑁2 …
768 768Figure 2: The depicted ﬁgure illustrates the RoBERTa-Sentinel architecture, wherein the dashed line
connecting RoBERTa-Base and MLP module indicates the non-propagation of gradient back to the
former.
Table 2: Training conﬁguration for RoBERTa-Sentinel and T5-Sentinel. Where “AdamW” refers to
the “Adaptive Momentum Estimation with Weight Decay” optimizer proposed by Loshchilov et al. in
[13]. “Cosine annealing” refers to the learning rate schedul proposed by Loschilov et al. in [14]
Hyper-Parameters RoBERTa-Sentinel T5-Sentinel
Epoch 15 5
Batch Size 512 512
Learning Rate 110 4510 4
Weight Decay 110 3110 3
Optimizer AdamW AdamW
Loss Function Cross entropy Cross entropy
Scheduler Cosine annealing Cosine annealing
Data Set OpenGPTText-Final OpenGPTText-Final
model while adapting it to the speciﬁc task at hand, we decided to “freeze” the RoBERTa model,
allowing the loss to only backpropagate through the MLP module.
LetErepresent the input embedding, Vrepresent the vocabulary size, and Hdenote the dimension
of the last hidden state in RoBERTa. The input text with length Ncan be expressed as a sequence
of embedding, E[CLS]; E1;; EN, where E[CLS]; Ei2RV. Here, E[CLS]denotes the embedding
of the special [CLS] token, as descried in the original BERT implementation [ 12]. We use the ﬁnal
hidden state vector T[CLS]2RHthat corresponds to the ﬁrst [CLS] token as the features of the input
text. This extracted feature vector Cis then forward to the MLP for classiﬁcation, as shown in ﬁgure
2.
The detailed training conﬁguration for RoBERTa-Sentinel can be found in table 2.
4.2 T5-Sentinel Model
The second methodwe proposed involves ﬁne-tuning the T5 model [ 15] for classiﬁcation tasks. Unlike
the RoBERTa-Sentinel which uses an MLP module to classify the hidden state vector of input, this
approach directly encodes the task as a sequence-to-sequence (seq-to-seq) problem.
During the training, the input sequence consists of a text sample from OpenGPTText-Final , and
the output sequence represents the classiﬁcation result as either “positive </s>” or “negative </s>”,
where “</s>” is the end-of-sequence token. During the inference, we limit the vocabulary down to
only two words (i.e. “positive” and “negative”), and select the one with the maximum probability as
the classiﬁcation result. This process is further shown in Figure 3.
5
𝑃ChatGPT =,𝑃Human =
𝐸1𝐸2Self-Attentio nFeed -forward MLP
𝐸𝑁𝐸<𝑠> ⋯T5 Encoder Block
⋯×6
Masked Multi -head AttentionMasked Multi -head AttentionT5 Decoder Block
×6
𝐸<𝑃𝐴𝐷>Feed Forward⋯Next -word
Probability Distribution“Positive” “Negative”Figure 3: Architecture for T5-Sentinel. After input the entire token sequence, we provide the T5-
Decoder with a <PAD> token and predict if the input text is by human or generated based on the
probability of speciﬁc word “Positive” and “Negative” in the output word probability distribution.
The detailed training conﬁguration of T5-Sentinel can be found in table 2.
5 Evaluation
5.1 Evaluation Metric
In our study, we assess the performance of the RoBERTa-Sentinel and T5-Sentinel through the
application of ﬁve distinct evaluation metrics, namely the F1 score, receiver operating characteristic
(ROC) curve, detection error trade-off (DET), area under curve (AUC), and model conﬁdence score.
In this paper, the term “positive” refers to the input text is ChatGPT-generated, while “negative” ,
means that the data is written by human.
Given the true positive ( TP), true negative ( TN), false positive ( FP) and false negative ( FN) count,
we can calculate the metrics as following:
F1 Score =TP
TP+1
2(FP+FN)
TPR =TP
TP+FNFPR =FP
FP+TNTNR =TN
TN+FPFNR =FN
FN+TP
5.2 F1 Score, False Positive Rate and False Negative Rate
The F1 score, false positive rate and false negative rate of RoBERTa-Sentinel and T5-Sentinel is
evaluated on original data set ( OpenGPTText ), cleaned data set ( OpenGPTText-Final ), and the
GPT2-Output1data set [ 16]. The evaluation results when taking 0:5as the threshold probability for
positive are shown in the table 3. For more detailed data on evaluation result, we included the true
positive rate, true negative rate and sample count for each metric in table 6 in appendix B.
An important observation is that even though T5-Sentinel and RoBERTa-Sentinel models exhibit
high accuracy in the OpenGPTText data set, both prior to and post cleaning, they do not perform
as effectively on the GPT2-Output data set, displaying an exceptionally high FNR. This disparity
may be attributed to the distinctive quality of text generated by GPT2 and ChatGPT models, as well
as the dissimilar nature of the samples in the OpenGPTText data set, which are all rephrased from
1There exist multiple variants of GPT2-Output data set, unless explicitly stated otherwise, in this paper we
refer to the GPT2-Output data set with GPT2 Extra Large (1542M parameter) with pure sampling method.
6
Table 3: The evaluation result for T5-Sentinel, RoBERTa-Sentinel, ZeroGPT [ 17], OpenAI-Detector
[18], and GPT-2 Detector from Solaiman et al. [ 4] on three data sets under threshold probability of
0:5. F1 stands for “F1-score”. FPR and FNR data are in percentage.
Model OpenGPTText-Final OpenGPTText GPT2-Output
F1 FPR FNR F1 FPR FNR F1 FPR FNR
T5 0.98 2.8 1.3 0.98 3.5 1.3 0.06 5.9 96.7
RoBERTa 0.94 9.0 3.2 0.89 21.6 1.9 0.16 17.2 89.6
ZeroGPT 0.43 26.3 65.0 0.40 16.5 71.3 0.14 23.4 90.5
OpenAI-Detector 0.32 4.9 79.8 0.26 1.6 85.2 0.66 13.6 44.0
GPT2 0.23 2.8 86.8 0.22 4.1 87.2 0.93 6.4 7.4
Table 4: AUC Value for each combination of data set and model
Model OpenGPTText-Final OpenGPTText GPT2-Output
T5-Sentinel 0.993 0.992 0.463
RoBERTa-Sentinel 0.986 0.976 0.423
ZeroGPT 0.526 0.555 0.413
OpenAI-Detector 0.765 0.752 0.770
GPT2-Detector 0.610 0.600 0.976
human-written articles, in contrast to the GPT2-Output data set that contains randomly generated
text.
Likewise, it is worth noting that the baseline model, GPT2-Detector by Solaiman et al., did not succeed
in transferring its learned experience from the GPT2 output detection task to the task of detecting
ChatGPT generated text, despite the ﬁndings presented in [ 4], which indicate that GPT2-Detector is
capable of detecting diverse variants of the GPT2 model.
5.3 ROC / DET Curve and AUC
The ROC curve is a common graph used to evaluate and compare classiﬁers and can explicitly
visualize the sensitivity/speciﬁcity trade-off of classiﬁer for all thresholds [ 19]. The ROC curve of
T5-Sentinel, RoBERTa-Sentinel and GPT2-Detector on OpenGPTText ,OpenGPTText-Final and
GPT2-Output are shown in ﬁgure 4 separately. Upon analyzing the ROC curves for the same model
across different data sets, as illustrated in Figure 5, we observe that the T5-Sentinel demonstrates
greater robustness as compared to RoBERTa-Sentinel.
The area under curve (AUC) is a single-number summary for the ROC curve. The AUC result for
each combination of model and dataset is listed in table 4.
We also plot the detector error trade-off (DET) curves across different models (ﬁgure 6) and across
different data sets (ﬁgure 7).
0.0 0.2 0.4 0.6 0.8 1.0
False Positive Rate0.00.20.40.60.81.0True Positive RateROC Curves of T5-Sentinel, RoBERT a-Sentinel, ZeroGPT
OpenAI-Detector and GPT2-Detector on OpenGPTT ext-Final
T5-Sentinel
RoBERT a-Sentinel
ZeroGPT
OpenAI-Detector
GPT2-Detector
0.0 0.2 0.4 0.6 0.8 1.0
False Positive Rate0.00.20.40.60.81.0True Positive RateROC Curves of T5-Sentinel, RoBERT a-Sentinel, ZeroGPT
OpenAI-Detector and GPT2-Detector on OpenGPTT ext
T5-Sentinel
RoBERT a-Sentinel
ZeroGPT
OpenAI-Detector
GPT2-Detector
0.0 0.2 0.4 0.6 0.8 1.0
False Positive Rate0.00.20.40.60.81.0True Positive RateROC Curves of T5-Sentinel, RoBERT a-Sentinel, ZeroGPT
OpenAI-Detector and GPT2-Detector on GPT2-Output
T5-Sentinel
RoBERT a-Sentinel
ZeroGPT
OpenAI-Detector
GPT2-Detector
Figure 4: ROC Curves for models across different data sets. OpenGPTText-Final (Left),
OpenGPTText (Middle), and GPT2-Output (Right)
7
0.0 0.2 0.4 0.6 0.8 1.0
False Positive Rate0.00.20.40.60.81.0True Positive RateROC Curves of T5-Sentinel Across Three Data Sets
OpenGPTT ext-Final
OpenGPTT ext
GPT2-Output
0.0 0.2 0.4 0.6 0.8 1.0
False Positive Rate0.00.20.40.60.81.0True Positive RateROC Curves of RoBERT a-Sentinel Across Three Data Sets
OpenGPTT ext-Final
OpenGPTT ext
GPT2-OutputFigure 5: ROC Curves for same model under different data sets T5-Sentinel (Left) and RoBERTa-
Sentinel (Right). Note that the performance of RoBERTa-Sentinel signiﬁcantly deteriorates when
transfer to original version of OpenGPTText while T5-Sentinel does not.
103
102
101
100
False Positive Rate103
102
101
100False Negative RateDET Curves of T5-Sentinel, RoBERT a-Sentinel, ZeroGPT 
OpenAI-Detector GPT2-Detector on OpenGPTT ext-Final
T5-Sentinel
RoBERT a-Sentinel
ZeroGPT
OpenAI-Detector
GPT2-Detector
103
102
101
100
False Positive Rate103
102
101
100False Negative RateDET Curves of T5-Sentinel, RoBERT a-Sentinel, ZeroGPT 
 OpenAI-Detector and GPT2-Detector on OpenGPTT ext
T5-Sentinel
RoBERT a-Sentinel
ZeroGPT
OpenAI-Detector
GPT2-Detector
103
102
101
100
False Positive Rate103
102
101
100False Negative RateDET Curves of T5-Sentinel, RoBERT a-Sentinel, ZeroGPT
OpenAI-Detector and GPT2-Detector on GPT2-Output
T5-Sentinel
RoBERT a-Sentinel
ZeroGPT
OpenAI-Detector
GPT2-Detector
Figure 6: DET Curves of different models under OpenGPTText-Final (Left), OpenGPTText (Mid-
dle) and GPT2-Output (Right) under logarithmic axis.
5.4 Conﬁdence Score
Assessing the reliability and conﬁdence of a machine learning model’s predictions is crucial for
evaluating its performance. To this end, we calculated conﬁdence scores for each combination of
data sets and models, and plot them in ﬁgure 8. The resulting conﬁdence scores range from 0 to 1
and provide a measure of the model’s certainty about its predictions.
In our analysis, we investigated the distribution of conﬁdence scores and their correspondence with
accuracy. Our result indicates that the T5-Sentinel model achieved higher conﬁdence scores compared
to RoBERTa-Sentinel. In contrast, the RoBERTa-Sentinel model had lower conﬁdence scores than
T5-Sentinel and showed greater conﬁdence when detecting text generated by human than that by
Chat-GPT.
Overall, our ﬁndings suggest that the T5-Sentinel model is more reliable and decisive than RoBERTa-
Sentinel, particularly when dealing with OpenGPTText . Further investigation is needed to fully
understand the reasons for these differences and to optimize the performance of these models for
speciﬁc applications.
103
102
101
100
False Positive Rate103
102
101
100False Negative RateDET Curves of T5-Sentinel Across Three Data Sets
OpenGPTT ext-Final
OpenGPTT ext
GPT2-Output
103
102
101
100
False Positive Rate103
102
101
100False Negative RateDET Curves of RoBERT a-Sentinel Across Three Data Sets
OpenGPTT ext-Final
OpenGPTT ext
GPT2-Output
Figure 7: DET Curves of T5-Sentinel (Left) and RoBERTa-Sentinel (Right) on different data sets.
8
0.0 0.2 0.4 0.6 0.8 1.0050010001500200025003000Data Count
020406080100
Confidence level (%)Confidence level of T5-Sentinel on
 OpenGPTT ext-Final, OpenGPTT ext data sets
OpenGPTT ext-Final
OpenGPTT ext
0.0 0.2 0.4 0.6 0.8 1.00500100015002000Data Count
020406080100
Confidence level (%)Confidence level of RoBERT a-Sentinel on
 OpenGPTT ext-Final, OpenGPTT ext data sets
OpenGPTT ext-Final
OpenGPTT extFigure 8: Conﬁdence Scores for T5-Sentinel and RoBERTa-Sentinel on OpenGPTText-Final and
OpenGPTText data set. The histogram represents the number of sample under certain range of
probability for the sample to be positive.
6
 4
 2
 0 2 4 6 8 106
4
2
0246PCA projection of decoder hidden state
T5-Sentinel on OpenGPTT ext-Final
OpenWebT ext
OpenGPTT ext
4
 3
 2
 1
 0 1 2 3 4 52.0
1.5
1.0
0.5
0.00.51.01.52.0PCA projection of hidden state of
RoBERT a-Sentinel on OpenGPTT ext-Final
OpenWebT ext
OpenGPTT ext
Figure 9: PCA projection of hidden states for T5-Sentinel (Left) and RoBERTa-Sentinel (Right)
6 Interpretability Study
6.1 Principal Component Analysis on Hidden State
To offer greater insight into the functioning of the models we proposed, T5-Sentinel and RoBERTa-
Sentinel, we conducted a PCA on their respective hidden states.
For RoBERTa-Sentinel, we extracted the hidden state from last layer of attached MLP and the output
of last decoder block for T5-Sentinel and recorded their values with input of all data in test set
sampled from OpenGPTText-Final . As shown in ﬁgure 9, both models successfully mapped the
input text into two different clusters in hidden space, indicating that both models were able to extract
implicit characteristics of ChatGPT rephrased text.
To investigate the properties of the data along each direction of the projection subspace, we conducted
a sampling of the data point outliers in the PCA projection subspace.
Figure 10 displays the position of four samples in the PCA projection subspace. Upon manual
inspection of these samples, we discovered that Sample 1 was a brief car advertisement that utilized
simple language and comprised of very short paragraphs (split by images in the original web page).
Sample 2 was a sport news article with lengthy paragraphs, while Sample 3 constituted a sequence
of developing tool names that lacked any actual meaning. Sample 4 was a brief report on children’s
attitudes towards clowns. These observations suggest that our model may have learned to distinguish
the length of paragraphs and potentially discern whether a given text sample is informative and
meaningful. We have provided detailed textual samples along with their unique identiﬁers (UIDs)
from the OpenGPTText data set in Appendix B.
9
4
 2
 0 2 4 62
1
0123Outliers in Hidden Feature Space after PCA
RoBERT a-Sentinel on OpenGPTT ext-Final Dataset
OpenWebT ext
OpenGPTT ext
Sample 1Sample 2
Sample 3
Sample 4Figure 10: Outliers in PCA projection space drawn for manual inspection.
6.2 Integrated Gradient
We utilized the integrated gradient analysis technique, as proposed by Sundararajan et al. [ 20], to gain
insights into the contribution of individual tokens in a given input text towards the overall “GPT-ness”
of the text. Our approach involved initially passing the input text through the model and computing
the loss function under the assumption that the text label was “human”. Following this, we executed
back-propagation to obtain the gradients associated with each input token. This statement conformed
to the formal style and technical language typically employed in academic writing.
The rationale underlying our method is rooted in the observation that tokens with gradients close to
zero tend to align well with the human label, thereby necessitating minimal modiﬁcation. Conversely,
tokens with large gradients are indicative of a misalignment with the human label, suggesting a higher
degree of resemblance to GPT-like characteristics.
We further developed a visualization tool that shows the contribution of each input token to the overall
GPT-ness of the text. The darker the background token is, the more GPT-like that token is.
Below we show a sample2visualization result drawn from the test set of OpenGPTText-Final data set
before and after the rephrasing.
Original Text: Predict as human with probability of 0.998, with conﬁdence of 0.994
Applestarted anavalancheofactivitywith theintroductionoftheiPad .Com panies shifted
gear stogoafterthisundiscovered new tablet market.Inspite ofthenumberofplayersin
tablets ,nocompany hasdiscovered themagic bullettoknock theiPad offthetopofthetablet
heap .Colleague Adrian Kings ley-Hugheshasathought fulpiece blamingAma zon
andGoogle forkilling thetablet market.HisreasoningisthatbyreleasingtheKindleFire
andtheNex us7at$199,Ama zonandGoogle have started a"race tothebottom"ofthe
tablet marketthatwillensure noprofitabil ityforanyone.Adrian ’sreasoningissolid ,but
itoverlook sonething Ihave said foralong time .There isnoproven tablet market.(...
Truncated)
Rephrased Text: Predict as generated with probability of 1.000, with conﬁdence of 0.985
2With data unique identiﬁer (UID): [urlsf_subset00]-[309279]
10
60
 40
 20
 0 20 40 6040
20
02040t-SNE Plot on Hidden State of T5-Sentinel
on OpenGPTT ext-Final
OpenWebT ext
OpenGPTT ext
80
 60
 40
 20
 0 20 40 60 8040
20
02040t-SNE Plot on Hidden State of RoBERT a-Sentinel
on OpenGPTT ext-Final
OpenWebT ext
OpenGPTT extFigure 11: Hidden states of T5-Sentinel (Left) and RoBERTa-Sentinel (Right) on urlsf-04 subset
ofOpenGPTText-Final after t-SNE dimensionality reduction.
Followingtherelease oftheiPad ,thetablet marketbecame apopulararea forcompaniesto
explore .Despite many companiesenteringthemarket,noonehasmanaged tooutperform
theiPad onsales .There isabeliefthatAma zonandGoogle have caused this,duetothe
release oftheKindleFireandNex us7at$199,startinga"race tothebottom."There is
aconcern thatthiswillensure there willbenoprofitabil ityforanyone.How ever ,thisbelief
overlook sthefactthatthere isnoproven marketfortablets ,only aproven marketforiPad s
.Other than Apple,Samsung istheonly company with notable tablet sales .Even though
they released severaltablets ,invariousshapes andsizes ,they stillcould notcompete with
theiPad .(...Truncated)
6.3 t-distributed Stochastic Neighbor Embedding Visualization
t-distributed Stochastic Neighbor Embedding (t-SNE) projection proposed by Maatan et al. [ 21] is
applied on the hidden state vector of both T5-Sentinel and RoBERTa-Sentinel. Results in ﬁgure 11
indicate that T5-Sentinel model can better separate the data set, which aligns with the performance of
both models on test data set.
7 Future Work
Although our current model has shown promising results, there are certain limitations in our current
model. First and foremost, both T5-Sentinel and RoBERTa-Sentinel are trained with English corpus
only. As a result, their performance on other languages such as Spanish or Chinese may not be
optimal. To address this limitation, ﬁne-tuning the models with non-English text can be helpful.
However, it’s worth noting that the pretrained version of the T5 model only supports English, French,
Romanian, and German. Therefore, classiﬁcation tasks involving languages other than these may
require more than just ﬁne-tuning alone.
In addition, the OpenGPTText-Final data set is collected with the prompt “ Rephrase the fol-
lowing paragraph by paragraph ”, so the model trained on such data set might not perform
well to other language tasks that ChatGPT is popularly used on, such as question answering or text
generation. In the future, we plan to collect data sets involving a different textual context, like eli5
[22] and SQuAD [23], to further assess the accuracy of the RoBERTa-Sentinel and T5-Sentinel on
different tasks.
8 Conclusion
In conclusion, we have introduced a high-quality data set called OpenGPTText , which we have
rephrased using the ChatGPT model. Additionally, we have designed, implemented, and trained
11
two text classiﬁcation models using RoBERTa and T5 architectures. Our models have achieved
remarkable results, with accuracy exceeding 97% on the test data set, as evaluated using various
metrics.
Moreover, we have conducted an interpretability study to demonstrate our models’ ability to extract
and differentiate key features between human-written and ChatGPT-generated text. The study’s
results show that our models are effective in identifying the differences between the two types of text,
providing insight into the strengths and limitations of the models and demonstrating their potential
for real-world applications.
9 Acknowledgement
We would like to express our sincere appreciation to Professor Bhiksha Raj and our TA mentor Liangze
(Josh) Li for their invaluable guidance, insightful comments, and constant support throughout the
course of this research. Their expertise in the ﬁeld have been instrumental in shaping our work.
References
[1]Ganesh Jawahar, Muhammad Abdul-Mageed, and Laks V . S. Lakshmanan. Automatic detection
of machine generated text: A critical survey. CoRR , abs/2011.01314, 2020.
[2]Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin,
Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton,
Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano,
Jan Leike, and Ryan Lowe. Training language models to follow instructions with human
feedback, 2022.
[3]Ganesh Jawahar, Muhammad Abdul-Mageed, and Laks V . S. Lakshmanan. Automatic detection
of machine generated text: A critical survey. CoRR , abs/2011.01314, 2020.
[4]Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-V oss, Jeff Wu, Alec
Radford, Gretchen Krueger, Jong Wook Kim, Sarah Kreps, Miles McCain, Alex Newhouse,
Jason Blazakis, Kris McGufﬁe, and Jasmine Wang. Release strategies and the social impacts of
language models, 2019.
[5]Daphne Ippolito, Daniel Duckworth, Chris Callison-Burch, and Douglas Eck. Automatic
detection of generated text is easiest when humans are fooled. In Annual Meeting of the
Association for Computational Linguistics , 2019.
[6]Sebastian Gehrmann, Hendrik Strobelt, and Alexander M. Rush. GLTR: statistical detection
and visualization of generated text. CoRR , abs/1906.04043, 2019.
[7]Rowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi, Franziska Roes-
ner, and Yejin Choi. Defending against neural fake news. In H. Wallach, H. Larochelle,
A. Beygelzimer, F. d 'Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Informa-
tion Processing Systems , volume 32. Curran Associates, Inc., 2019.
[8]Aaron Gokaslan and Vanya Cohen. Openwebtext corpus. http://Skylion007.github.io/
OpenWebTextCorpus , 2019.
[9]Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language
models are unsupervised multitask learners. In NeurIPS , 2019.
[10] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike
Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining
approach, 2019.
[11] Dan Hendrycks and Kevin Gimpel. Bridging nonlinearities and stochastic regularizers with
gaussian error linear units. ArXiv , abs/1606.08415, 2016.
[12] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: pre-training of
deep bidirectional transformers for language understanding. CoRR , abs/1810.04805, 2018.
[13] Ilya Loshchilov and Frank Hutter. Fixing weight decay regularization in adam. CoRR ,
abs/1711.05101, 2017.
12
[14] Ilya Loshchilov and Frank Hutter. SGDR: stochastic gradient descent with restarts. CoRR ,
abs/1608.03983, 2016.
[15] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,
Yanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a uniﬁed
text-to-text transformer. CoRR , abs/1910.10683, 2019.
[16] OpenAI. Gpt2-output. https://github.com/openai/gpt-2-output-dataset , 2019.
[17] ZeroGPT. AI Detector. https://www.zerogpt.com , January 2023.
[18] OpenAI. https://beta.openai.com/ai-text-classifier , January 2023.
[19] Francisco Melo, Werner Dubitzky, Olaf Wolkenhauer, Kwang-Hyun Cho, and Hiroki Yokota.
Receiver Operating Characteristic (ROC) Curve , pages 1818–1823. Springer New York, New
York, NY , 2013.
[20] Mukund Sundararajan, Ankur Taly, and Qiqi Yan. Axiomatic attribution for deep networks. In
International Conference on Machine Learning , 2017.
[21] Laurens van der Maaten and Geoffrey Hinton. Visualizing data using t-SNE. Journal of Machine
Learning Research , 9:2579–2605, 2008.
[22] Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, and Michael Auli.
ELI5: long form question answering. In Anna Korhonen, David R. Traum, and Lluís Màrquez,
editors, Proceedings of the 57th Conference of the Association for Computational Linguistics,
ACL 2019, Florence, Italy, July 28- August 2, 2019, Volume 1: Long Papers , pages 3558–3567.
Association for Computational Linguistics, 2019.
[23] Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. SQuAD: 100,000+ ques-
tions for machine comprehension of text. In Proceedings of the 2016 Conference on Empirical
Methods in Natural Language Processing , pages 2383–2392, Austin, Texas, November 2016.
Association for Computational Linguistics.
13
Table 5: Baseline evaluation on GPT2-output data set
Small Medium Large Extra Large
Metrics top- k pure top- k pure top- k pure top- k pure
Accuracy 0:9648 0 :9623 0 :9627 0 :9567 0 :9616 0 :9449 0 :9498 0 :9310
False Positive 0:0070 0 :0122 0 :0114 0 :0238 0 :0137 0 :0472 0 :0376 0 :0734
False Negative 0:0319 0 :0319 0 :0319 0 :0319 0 :0319 0 :0319 0 :0319 0 :0319
Figure 12: Confusion matrices of baseline model on GPT2-output data set under pure sampling
method
A GPT2-Detector Baseline Analysis
A.1 Evaluation on GPT2-Baseline
We reproduced the GPT2-Detector proposed by Solaiman et al. [ 4] as the baseline model and
performed evaluation on GPT2 output data set released by OpenAI [ 16]. The results are shown below.
The GPT2-output data set contains random output from four variants of GPT2 model: small (117M
parameter), medium (354M parameter), large (762M parameter) and extra-large (1542M parameter)
and we have evaluate our baseline model on all of them. The result is shown in table 5.
The confusion matrices for every variant (small, medium, large, extra-large) and every sampling
method (top- kand pure) is shown in ﬁgure 12 and ﬁgure 13.
A.2 Trend Between Language Model Scale and Classiﬁcation Accuracy
When running baseline test of GPT2-Detector, we noticed that there is an approximately linear
relationship between classiﬁcation accuracy and the scale of language model, as illustratd in 14.
A.3 PCA Analysis for Baseline Model
Despite the baseline model’s strong performance in detecting GPT-2 generated content, it encounters
signiﬁcant challenges when tasked with detecting GPT-3.5 generated content. In fact, without any
additional training, the baseline model achieved a mere 54.98% accuracy on the OpenGPTText
dataset, only slightly better than random chance. This signiﬁcant drop in accuracy highlights the
challenges of differentiating between human-generated and GPT-3.5 generated content, likely due to
the increased complexity of the GPT-3.5 model.
14
Figure 13: Confusion matrices of baseline model on GPT2-output data set under top- ksampling
(k= 40 )
200 400 600 800 1000 1200 1400 1600
#Parameter in GPT2 variant (Million)0.750.800.850.900.951.00Accuracy
0.9620.965
0.9570.963
0.9450.962
0.9310.95Accuracy v.s. #Parameters in GPT2 variants
Random Sampling
T op-k Sampling (k=40)
200 400 600 800 1000 1200 1400 1600
#Parameter in GPT2 variant (Million)0.000.050.100.150.200.25False Negative Rate
0.0070.012
0.0110.023
0.0130.046
0.0370.074False positive rate v.s. #Parameters in GPT2 variants
Random Sampling
T op-k Sampling (k=40)
Figure 14: As the number of parameter in language model increase, the detector’s accuracy decreases
linearly, while the false positive rate increases.
Figure 15: PCA Projection: GPT-2 vs. GPT-3.5 Turbo
15
Another notable observation is the difference in PCA projections between GPT-2 and GPT-3.5
generated content. The PCA projection for GPT-2 indicates that human-generated and GPT-2
generated content are clearly distinguishable from each other. However, the same distinction is not as
clear in the GPT-3.5 projection, as shown in ﬁgure 15.
16
Table 6: Evaluation Result on OpenGPTText-Final (Row 1-3), OpenGPTText-Original (Row 4-7),
and GPT2-Output (Row 8-11). TPR stands for “True Positive Rate”, TPC stands for “True Positive
Count”, TNR stands for “True Negative Rate”, TNC stands for “True Negative Count”.
Model Accuracy TPR, (TPC) TNR, (TNC) FPR, (FPC) FNR, (FNC)
T5 97.98% 98.71%, (2906) 97.25%, (2863) 2.75%, (81) 1.29%, (38)
RoBERTa 93.92% 96.81%, (2850) 91.03%, (2680) 8.97%, (264) 3.19%, (94)
OpenAI 57.68% 20.24%, (596) 95.11%, (2800) 4.89%, (144) 79.76%, (2348)
ZeroGPT 54.36% 34.99%, (1030) 73.74%, (2171) 26.26%, (773) 65.01%, (1914)
GPT2 38.5% 13.21%, (389) 97.16%, (1233) 2.84%, (36) 86.79%, (2555)
T5 97.64% 98.74%, (2907) 96.54%, (2842) 3.46%, (102) 1.26%, (37)
RoBERTa 88.28% 98.13%, (2889) 78.43%, (2309) 21.57%, (635) 1.87%, (55)
OpenAI 56.64% 14.84%, (437) 98.44%, (2898) 1.56%, (46) 85.16%, (2507)
ZeroGPT 56.1% 28.67%, (844) 83.53%, (2459) 16.47%, (485) 71.33%, (2100)
GPT2 37.86% 12.84%, (378) 95.9%, (1217) 4.1%, (52) 87.16%, (2566)
T5 48.68% 3.3%, (165) 94.06%, (4703) 5.94%, (297) 96.7%, (4835)
RoBERTa 46.56% 10.36%, (518) 82.76%, (4138) 17.24%, (862) 89.64%, (4482)
OpenAI 71.22% 56.02%, (2801) 86.42%, (4321) 13.58%, (679) 43.98%, (2199)
ZeroGPT343.09% 9.52%, (476) 76.64%, (3832) 23.36%, (1168) 90.48%, (4522)
GPT2 93.1% 92.58%, (4629) 93.62%, (4681) 6.38%, (319) 7.42%, (371)
B Detailed Information for Evaluation
B.1 Evaluation Result
As shown in table 5. The metrics are calculated under the positive probability threshold of 0:5.
B.2 Content Sample
B.2.1 Sample 1 - [urlsf_subset04]-[236996]-web
Lexus IS 250 is the entry model among IS sedans . Pictured is the
optional F Sport package that firms already stiff suspension and
adds some distinguishing visuals . ( Photo11 : Lexus )
Lexus gave us enough go - fast imagery in its Super Bowl ads last Sunday
that it almost seemed to be saying , "See , see , are too sporty ."
And , yes , some malingerers still might be insisting , "Are not ," and
need nudging .
After all , Lexus ’ reputation for years has been luxury at the expense
of handling and performance . But the brand is trying to transform so
that you ’ll compare it with BMW instead of Buick .
The ES , at the lower end , and the LS , at the top , still could be
considered luxo - machines more than yippee - mobiles . But most Lexus
models we ’ve driven lately behave in sporty fashion when prodded
that direction by the driver .
(... Truncated )
B.2.2 Sample 2 - [urlsf_subset04]-[246672]-gpt
After succumbing to a hip injury , Nick Kyrgios has come to the
decision to take rest and heal . This has led him to reflect on 2017 ,
with its highs and lows , from consecutive wins against great tennis
players to the difficulties he faced at Grand Slams . However , his
fondest memories were from team events , particularly the Laver Cup
and the Davis Cup . Kyrgios reveals that tennis can be a lonely sport
, and he often struggles with it. However , he praises the team
3ZeroGPT failed to process two data entries (with ID: 255332 and 258673 in xl-1542M.test.jsonl ) in
the GPT2-Output data set, those two entries are not counted in the calculation of metrics.
17
spirit in Davis Cup , highlighting how they all support each other ,
win or lose , and says it made him feel like he was part of the team .
Rusty , Davis Cup captain , created a WhatsApp group a year and a half
ago , which includes all the Davis Cup players . Kyrgios recounts how ,
after his semi - final win in Beijing , his phone was flooded with
loyal messages from the coaches and players . This sparked his
realization that it had become bigger than tennis , and they had
become a family trying to keep in touch no matter how far apart they
all were . He feels it has helped provide a support system for
everyone , both on and off the court , at a time when they really
needed it the most .
(... Truncated )
B.2.3 Sample 3 - [urlsf_subset04]-[230559]-web
Add DevOps Tools to your Pipeline
Densify XL Impact Bitbucket Bitbucket Server Bower Crucible Deveo
Fisheye Gerrit Git GitHub GitLab Gogs Helix ISPW Kallithea Mercurial
Micro Focus AccuRev Micro Focus StarTeam Perforce HelixCore
Rational Clearcase Rational Team Concert Subversion Team Foundation
Server Team Foundation Version Control
(... Truncated )
Kubernetes Engine Kubernetes Linux Containers Marathon Mesos
Mesosphere DC/OS Nomad OpenVZ Portainer Rancher Solaris Containers
Supergiant Swarm Sysdig Tectonic Weaveworks rkt OpsGenie DBmaestro
Datical Delphix Flyway Idera Liquibase Quest Toad Redgate Redgate
SQL Toolbelt
Add tools from the Periodic Table of DevOps or select from the full
list above .
Click " Visualize My Pipeline !" to view your pipeline in the DevOps
Diagram Generator .
B.2.4 Sample 4 - [urlsf_subset04]-[313139]-web
A carnival reveller dressed as a clown celebrates on the street in
Berlin February 18, 2007. REUTERS / Pawel Kopczynski
LONDON ( Reuters ) - Bad news for Coco and Blinko -- children don ’t like
clowns and even older kids are scared of them .
The news that will no doubt have clowns shedding tears was revealed in
a poll of youngsters by researchers from the University of
Sheffield who were examining how to improve the decor of hospital
children ’s wards .
The study , reported in the Nursing Standard magazine , found all the
250 patients aged between four and 16 they quizzed disliked the use
of clowns , with even the older ones finding them scary .
"As adults we make assumptions about what works for children ," said
Penny Curtis , a senior lecturer in research at the university .
"We found that clowns are universally disliked by children . Some found
them quite frightening and unknowable ."
(End of File )
18
